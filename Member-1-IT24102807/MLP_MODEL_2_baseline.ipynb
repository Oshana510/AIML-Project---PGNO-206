{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSmB-C-L_9Qt",
        "outputId": "e7dce577-5c64-42bf-c8bb-3fabde689493"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 1: Import Required Libraries**"
      ],
      "metadata": {
        "id": "mMLcdTv9CfHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "QbsjLoHNAPSi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 2: Load Dataset**"
      ],
      "metadata": {
        "id": "JP9Bu7HbCi2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('df_with_stockcode_rfm.csv')"
      ],
      "metadata": {
        "id": "Hpeu1Ym_AQMh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check first few rows to understand the data\n",
        "print(data.shape)\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eFbjsViATlo",
        "outputId": "f6280189-aa1a-4f7e-d649-2f9eefa648f3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12052, 1557)\n",
            "   UnitPrice  QuantityAbsolute  TotalAmount      Year     Month       Day  \\\n",
            "0  -0.787370         -0.009966    -0.468966  0.269665  1.306861 -0.678858   \n",
            "1  -0.265540          1.650565     1.793874  0.269665 -1.001465  0.480271   \n",
            "2  -0.787370          2.204075     0.963211  0.269665 -0.135843 -0.910684   \n",
            "3   0.281438         -0.840232    -0.762562  0.269665 -0.424384 -1.606161   \n",
            "4  -1.309200          0.543544    -0.824146  0.269665  0.441239 -0.215206   \n",
            "\n",
            "   DayOfWeek      Hour StockCode  Quantity  ... wreath  writing  yellow  \\\n",
            "0   0.840102 -1.216770    85049A         4  ...    0.0      0.0     0.0   \n",
            "1  -0.817183 -1.624390    85099B        10  ...    0.0      0.0     0.0   \n",
            "2   0.287673 -1.216770     21993        12  ...    0.0      0.0     0.0   \n",
            "3  -0.264755  0.821327     22699        -1  ...    0.0      0.0     0.0   \n",
            "4  -0.817183 -0.401531     23002         6  ...    0.0      0.0     0.0   \n",
            "\n",
            "   yellowblue  youre  yuletide  zinc  Recency  Frequency  Monetary  \n",
            "0         0.0    0.0       0.0   0.0        1          6     63.95  \n",
            "1         0.0    0.0       0.0   0.0       85          4     70.25  \n",
            "2         0.0    0.0       0.0   0.0      156          1     15.00  \n",
            "3         0.0    0.0       0.0   0.0      191          2     24.05  \n",
            "4         0.0    0.0       0.0   0.0       33          2     20.04  \n",
            "\n",
            "[5 rows x 1557 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check target column BEFORE splitting\n",
        "print(\"Unique values in IsCancelled column:\")\n",
        "print(data['IsCancelled'].unique())\n",
        "\n",
        "print(\"\\nNumber of NaN values in IsCancelled column:\")\n",
        "print(data['IsCancelled'].isna().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT6P_hKFAWJo",
        "outputId": "9fb83377-e105-40e6-b76f-8d2f1ad6643b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in IsCancelled column:\n",
            "[False  True]\n",
            "\n",
            "Number of NaN values in IsCancelled column:\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to string, strip spaces, and uppercase\n",
        "data['IsCancelled'] = data['IsCancelled'].astype(str).str.strip().str.upper()\n",
        "\n",
        "# Map to 1/0 (TRUE = 1, FALSE = 0)\n",
        "data['IsCancelled'] = data['IsCancelled'].map({'TRUE': 1, 'FALSE': 0})\n",
        "\n",
        "# Drop rows where target is NaN (invalid values)\n",
        "data = data.dropna(subset=['IsCancelled'])\n",
        "\n",
        "print(\"Rows remaining after cleaning target:\", data.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFGmEbgoAZn-",
        "outputId": "3204a1c6-4bad-42d6-bdb1-ad869c376739"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows remaining after cleaning target: 12052\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop(columns=['IsCancelled'])\n",
        "y = data['IsCancelled']\n",
        "\n",
        "X = pd.get_dummies(X, drop_first=True)"
      ],
      "metadata": {
        "id": "DG6i6XgZApE4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKhCm3GQAr33",
        "outputId": "0005c69a-8bba-4fd6-ed7c-ddb3aa139040"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (12052, 10457)\n",
            "y shape: (12052,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 3: Split train and test**"
      ],
      "metadata": {
        "id": "yjZZYSEdCpWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "DAt1zCWWA0QU"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Handle NaNs in features\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train = imputer.fit_transform(X_train)\n",
        "X_test = imputer.transform(X_test)"
      ],
      "metadata": {
        "id": "wfF74D5QA25E"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 4: Standardize**"
      ],
      "metadata": {
        "id": "RGnT1lzvCwW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "wRcOxjQRA6CX"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 5:Build MLP**"
      ],
      "metadata": {
        "id": "itbaUOqQC1MQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(X_train.shape[1],)))  # Input layer\n",
        "\n",
        "# First hidden layer with tanh activation\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.3))  # Dropout after first hidden layer\n",
        "\n",
        "# Second hidden layer with tanh activation\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.3))  # Dropout after second hidden layer\n",
        "\n",
        "# Output layer (sigmoid for binary classification)\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "bLp67PgJA81V"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 6:Compile the model**"
      ],
      "metadata": {
        "id": "5z8W4YJuCJ3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',              # Adaptive optimizer\n",
        "    loss='binary_crossentropy',    # Suitable for binary classification\n",
        "    metrics=['accuracy']           # Track accuracy during training\n",
        ")"
      ],
      "metadata": {
        "id": "qTbYsv_JA_xc"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 7: Train (fit) the model**"
      ],
      "metadata": {
        "id": "_OtEIPiZCN5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),  # Optional, to track test performance\n",
        "    epochs=100,                          # Number of passes over the data\n",
        "    batch_size=32,                      # Size of each mini-batch\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgb6CUn_BEYa",
        "outputId": "81a5ae1a-15a9-4b45-fcc6-cfd710c915b1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.6213 - loss: 0.7430 - val_accuracy: 0.7731 - val_loss: 0.4948\n",
            "Epoch 2/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8886 - loss: 0.2956 - val_accuracy: 0.8474 - val_loss: 0.4153\n",
            "Epoch 3/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9727 - loss: 0.0800 - val_accuracy: 0.8735 - val_loss: 0.4226\n",
            "Epoch 4/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9880 - loss: 0.0336 - val_accuracy: 0.8743 - val_loss: 0.5119\n",
            "Epoch 5/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9953 - loss: 0.0180 - val_accuracy: 0.8693 - val_loss: 0.6176\n",
            "Epoch 6/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9974 - loss: 0.0100 - val_accuracy: 0.8710 - val_loss: 0.6385\n",
            "Epoch 7/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.9964 - loss: 0.0120 - val_accuracy: 0.8805 - val_loss: 0.5827\n",
            "Epoch 8/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9985 - loss: 0.0094 - val_accuracy: 0.8627 - val_loss: 0.7285\n",
            "Epoch 9/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.0075 - val_accuracy: 0.8810 - val_loss: 0.6537\n",
            "Epoch 10/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9980 - loss: 0.0060 - val_accuracy: 0.8648 - val_loss: 0.7695\n",
            "Epoch 11/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9988 - loss: 0.0042 - val_accuracy: 0.8627 - val_loss: 0.8279\n",
            "Epoch 12/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9984 - loss: 0.0050 - val_accuracy: 0.8689 - val_loss: 0.7632\n",
            "Epoch 13/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9985 - loss: 0.0027 - val_accuracy: 0.8652 - val_loss: 0.8463\n",
            "Epoch 14/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9993 - loss: 0.0020 - val_accuracy: 0.8756 - val_loss: 0.7788\n",
            "Epoch 15/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9991 - loss: 0.0026 - val_accuracy: 0.8822 - val_loss: 0.6883\n",
            "Epoch 16/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9989 - loss: 0.0033 - val_accuracy: 0.8689 - val_loss: 0.8152\n",
            "Epoch 17/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9990 - loss: 0.0025 - val_accuracy: 0.8731 - val_loss: 0.7872\n",
            "Epoch 18/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9995 - loss: 0.0021 - val_accuracy: 0.8946 - val_loss: 0.6487\n",
            "Epoch 19/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.8922 - val_loss: 0.7451\n",
            "Epoch 20/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9995 - loss: 0.0012 - val_accuracy: 0.8801 - val_loss: 0.8914\n",
            "Epoch 21/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9995 - loss: 0.0021 - val_accuracy: 0.8619 - val_loss: 1.1348\n",
            "Epoch 22/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.9011e-04 - val_accuracy: 0.9054 - val_loss: 0.6699\n",
            "Epoch 23/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9991 - loss: 0.0041 - val_accuracy: 0.8855 - val_loss: 0.8687\n",
            "Epoch 24/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 6.4882e-04 - val_accuracy: 0.8768 - val_loss: 0.9486\n",
            "Epoch 25/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9994 - loss: 0.0013 - val_accuracy: 0.8926 - val_loss: 0.7519\n",
            "Epoch 26/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.2015e-04 - val_accuracy: 0.8851 - val_loss: 0.8477\n",
            "Epoch 27/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9998 - loss: 6.5765e-04 - val_accuracy: 0.9009 - val_loss: 0.6955\n",
            "Epoch 28/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9996 - loss: 6.9469e-04 - val_accuracy: 0.8785 - val_loss: 0.8970\n",
            "Epoch 29/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9999 - loss: 4.5081e-04 - val_accuracy: 0.8855 - val_loss: 0.9085\n",
            "Epoch 30/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9995 - loss: 0.0012 - val_accuracy: 0.8901 - val_loss: 0.9685\n",
            "Epoch 31/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9993 - loss: 0.0014 - val_accuracy: 0.8664 - val_loss: 1.3760\n",
            "Epoch 32/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.9995 - loss: 8.5109e-04 - val_accuracy: 0.8876 - val_loss: 1.0043\n",
            "Epoch 33/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9998 - loss: 0.0010 - val_accuracy: 0.9104 - val_loss: 0.7316\n",
            "Epoch 34/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.8859 - val_loss: 1.0176\n",
            "Epoch 35/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9994 - loss: 0.0041 - val_accuracy: 0.9005 - val_loss: 0.7531\n",
            "Epoch 36/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9992 - loss: 0.0022 - val_accuracy: 0.9071 - val_loss: 0.7492\n",
            "Epoch 37/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9998 - loss: 5.6507e-04 - val_accuracy: 0.8843 - val_loss: 1.1032\n",
            "Epoch 38/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9997 - loss: 0.0016 - val_accuracy: 0.8897 - val_loss: 0.9274\n",
            "Epoch 39/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9999 - loss: 3.7832e-04 - val_accuracy: 0.9025 - val_loss: 0.7878\n",
            "Epoch 40/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9997 - loss: 0.0010 - val_accuracy: 0.9096 - val_loss: 0.6520\n",
            "Epoch 41/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9965 - loss: 0.0166 - val_accuracy: 0.8731 - val_loss: 1.0595\n",
            "Epoch 42/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.9991 - loss: 0.0044 - val_accuracy: 0.9034 - val_loss: 0.7269\n",
            "Epoch 43/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9992 - loss: 0.0034 - val_accuracy: 0.8909 - val_loss: 0.8091\n",
            "Epoch 44/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9995 - loss: 6.4501e-04 - val_accuracy: 0.9170 - val_loss: 0.6295\n",
            "Epoch 45/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9989 - loss: 0.0035 - val_accuracy: 0.8976 - val_loss: 0.7735\n",
            "Epoch 46/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9997 - loss: 9.5211e-04 - val_accuracy: 0.8913 - val_loss: 0.8236\n",
            "Epoch 47/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.8830 - val_loss: 0.9130\n",
            "Epoch 48/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9998 - loss: 6.7422e-04 - val_accuracy: 0.8478 - val_loss: 1.3957\n",
            "Epoch 49/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 2.6965e-04 - val_accuracy: 0.8760 - val_loss: 1.0730\n",
            "Epoch 50/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.9476e-04 - val_accuracy: 0.8847 - val_loss: 0.9715\n",
            "Epoch 51/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 2.8920e-05 - val_accuracy: 0.8760 - val_loss: 1.1094\n",
            "Epoch 52/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 9.6197e-05 - val_accuracy: 0.8789 - val_loss: 1.1366\n",
            "Epoch 53/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 2.3515e-04 - val_accuracy: 0.8967 - val_loss: 0.8474\n",
            "Epoch 54/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9998 - loss: 4.9192e-04 - val_accuracy: 0.8992 - val_loss: 0.9074\n",
            "Epoch 55/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9998 - loss: 5.0428e-04 - val_accuracy: 0.9075 - val_loss: 0.8618\n",
            "Epoch 56/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9997 - loss: 7.5631e-04 - val_accuracy: 0.9054 - val_loss: 0.8704\n",
            "Epoch 57/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9998 - loss: 4.4474e-04 - val_accuracy: 0.8739 - val_loss: 1.2893\n",
            "Epoch 58/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9999 - loss: 1.5478e-04 - val_accuracy: 0.8967 - val_loss: 0.9745\n",
            "Epoch 59/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9999 - loss: 7.9948e-04 - val_accuracy: 0.8930 - val_loss: 1.0535\n",
            "Epoch 60/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9993 - loss: 0.0028 - val_accuracy: 0.8938 - val_loss: 0.9119\n",
            "Epoch 61/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 1.5190e-04 - val_accuracy: 0.9133 - val_loss: 0.8078\n",
            "Epoch 62/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9996 - loss: 0.0022 - val_accuracy: 0.9208 - val_loss: 0.8044\n",
            "Epoch 63/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.9988 - loss: 0.0051 - val_accuracy: 0.8855 - val_loss: 0.9661\n",
            "Epoch 64/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9994 - loss: 0.0016 - val_accuracy: 0.9009 - val_loss: 0.7342\n",
            "Epoch 65/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9995 - loss: 0.0017 - val_accuracy: 0.8785 - val_loss: 0.8949\n",
            "Epoch 66/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9992 - loss: 0.0039 - val_accuracy: 0.8946 - val_loss: 0.7664\n",
            "Epoch 67/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 2.2175e-04 - val_accuracy: 0.8946 - val_loss: 0.8364\n",
            "Epoch 68/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9054 - val_loss: 0.7384\n",
            "Epoch 69/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9999 - loss: 2.8377e-04 - val_accuracy: 0.9088 - val_loss: 0.7524\n",
            "Epoch 70/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9998 - loss: 0.0014 - val_accuracy: 0.9054 - val_loss: 0.7598\n",
            "Epoch 71/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9990 - loss: 0.0044 - val_accuracy: 0.9075 - val_loss: 0.6944\n",
            "Epoch 72/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9995 - loss: 0.0050 - val_accuracy: 0.9249 - val_loss: 0.6589\n",
            "Epoch 73/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9995 - loss: 0.0016 - val_accuracy: 0.9112 - val_loss: 0.8492\n",
            "Epoch 74/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9994 - loss: 0.0018 - val_accuracy: 0.9108 - val_loss: 0.8769\n",
            "Epoch 75/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9996 - loss: 9.4918e-04 - val_accuracy: 0.9029 - val_loss: 1.1062\n",
            "Epoch 76/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9978 - loss: 0.0070 - val_accuracy: 0.9038 - val_loss: 1.0922\n",
            "Epoch 77/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9969 - loss: 0.0203 - val_accuracy: 0.9282 - val_loss: 0.6738\n",
            "Epoch 78/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9953 - loss: 0.0232 - val_accuracy: 0.9320 - val_loss: 0.5674\n",
            "Epoch 79/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9978 - loss: 0.0075 - val_accuracy: 0.9208 - val_loss: 0.6327\n",
            "Epoch 80/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9989 - loss: 0.0074 - val_accuracy: 0.9262 - val_loss: 0.5647\n",
            "Epoch 81/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.9253 - val_loss: 0.5789\n",
            "Epoch 82/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9989 - loss: 0.0072 - val_accuracy: 0.9200 - val_loss: 0.6759\n",
            "Epoch 83/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.9983 - loss: 0.0056 - val_accuracy: 0.9150 - val_loss: 0.6722\n",
            "Epoch 84/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9994 - loss: 0.0028 - val_accuracy: 0.9216 - val_loss: 0.5857\n",
            "Epoch 85/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9989 - loss: 0.0028 - val_accuracy: 0.9229 - val_loss: 0.5602\n",
            "Epoch 86/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9989 - loss: 0.0050 - val_accuracy: 0.9241 - val_loss: 0.5126\n",
            "Epoch 87/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9987 - loss: 0.0038 - val_accuracy: 0.9150 - val_loss: 0.5869\n",
            "Epoch 88/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9995 - loss: 0.0013 - val_accuracy: 0.9245 - val_loss: 0.5149\n",
            "Epoch 89/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9983 - loss: 0.0081 - val_accuracy: 0.9212 - val_loss: 0.5472\n",
            "Epoch 90/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9994 - loss: 0.0019 - val_accuracy: 0.9212 - val_loss: 0.5408\n",
            "Epoch 91/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9993 - loss: 0.0011 - val_accuracy: 0.9162 - val_loss: 0.6745\n",
            "Epoch 92/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9994 - loss: 0.0034 - val_accuracy: 0.9299 - val_loss: 0.5955\n",
            "Epoch 93/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.9191 - val_loss: 0.7059\n",
            "Epoch 94/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9994 - loss: 0.0012 - val_accuracy: 0.9253 - val_loss: 0.6200\n",
            "Epoch 95/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 5.4794e-04 - val_accuracy: 0.9282 - val_loss: 0.6473\n",
            "Epoch 96/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 1.1343e-04 - val_accuracy: 0.9154 - val_loss: 0.8201\n",
            "Epoch 97/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9999 - loss: 1.7393e-04 - val_accuracy: 0.9058 - val_loss: 1.0120\n",
            "Epoch 98/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9997 - loss: 9.8050e-04 - val_accuracy: 0.9125 - val_loss: 0.9010\n",
            "Epoch 99/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9997 - loss: 6.3380e-04 - val_accuracy: 0.9042 - val_loss: 1.1682\n",
            "Epoch 100/100\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9993 - loss: 0.0051 - val_accuracy: 0.9266 - val_loss: 0.7434\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Probabilities\n",
        "y_train_prob = model.predict(X_train)\n",
        "y_test_prob = model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to 0/1 labels\n",
        "y_train_pred = (y_train_prob > 0.5).astype(int)\n",
        "y_test_pred = (y_test_prob > 0.5).astype(int)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxoudKSuBFZW",
        "outputId": "0c03db55-e3e8-4c73-e7af-b6d9d061c73b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 8: Evaluate the Model**"
      ],
      "metadata": {
        "id": "qWV9zeSIDKBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# F1 Scores\n",
        "f1_train = f1_score(y_train, y_train_pred)\n",
        "f1_test = f1_score(y_test, y_test_pred)\n",
        "\n",
        "# ROC AUC Scores\n",
        "roc_train = roc_auc_score(y_train, y_train_pred)\n",
        "roc_test = roc_auc_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"\\n--- Performance Comparison (Train vs. Test) ---\")\n",
        "print(f\"F1 Score (Training): {f1_train:.4f}\")\n",
        "print(f\"F1 Score (Test): {f1_test:.4f}\")\n",
        "print(f\"ROC AUC Score (Training): {roc_train:.4f}\")\n",
        "print(f\"ROC AUC Score (Test): {roc_test:.4f}\")\n",
        "\n",
        "# Accuracy, Confusion Matrix, Classification Report\n",
        "print(\"\\nAccuracy (Test):\", accuracy_score(y_test, y_test_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXmLDKF1BJq2",
        "outputId": "f7cf5a34-d1c5-4d31-f053-579b62fc9d19"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Performance Comparison (Train vs. Test) ---\n",
            "F1 Score (Training): 1.0000\n",
            "F1 Score (Test): 0.9247\n",
            "ROC AUC Score (Training): 1.0000\n",
            "ROC AUC Score (Test): 0.9276\n",
            "\n",
            "Accuracy (Test): 0.9265864786395687\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1147  117]\n",
            " [  60 1087]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.91      0.93      1264\n",
            "           1       0.90      0.95      0.92      1147\n",
            "\n",
            "    accuracy                           0.93      2411\n",
            "   macro avg       0.93      0.93      0.93      2411\n",
            "weighted avg       0.93      0.93      0.93      2411\n",
            "\n"
          ]
        }
      ]
    }
  ]
}